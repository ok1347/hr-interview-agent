{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a7f20b33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pymupdf in /home/yaya/rhagent/melo_env/lib/python3.12/site-packages (1.26.0)\n",
      "Requirement already satisfied: pytesseract in /home/yaya/rhagent/melo_env/lib/python3.12/site-packages (0.3.13)\n",
      "Requirement already satisfied: pillow in /home/yaya/rhagent/melo_env/lib/python3.12/site-packages (11.2.1)\n",
      "Requirement already satisfied: packaging>=21.3 in /home/yaya/rhagent/melo_env/lib/python3.12/site-packages (from pytesseract) (25.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install pymupdf pytesseract pillow\n",
    "import fitz  # PyMuPDF\n",
    "import pytesseract\n",
    "from PIL import Image\n",
    "import io\n",
    "\n",
    "def extract_text_with_ocr(page) -> str:\n",
    "    pix = page.get_pixmap(dpi=300)\n",
    "    image = Image.open(io.BytesIO(pix.tobytes(\"png\")))\n",
    "    text = pytesseract.image_to_string(image, lang=\"eng\")\n",
    "    return text.strip()\n",
    "\n",
    "def extract_text_from_pdf(path: str) -> str:\n",
    "    doc = fitz.open(path)\n",
    "    all_text = []\n",
    "\n",
    "    for page in doc:\n",
    "        text = page.get_text()\n",
    "        if text.strip():\n",
    "            all_text.append(text)\n",
    "        else:\n",
    "            ocr_text = extract_text_with_ocr(page)\n",
    "            all_text.append(ocr_text)\n",
    "\n",
    "    return \"\\n\".join(all_text).strip()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f3ce4b18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV:\n",
      " KROMBI YAHYA\n",
      "Dynamic and rigorous engineer seeking a position in the ﬁeld\n",
      "of Data/Gen IA.\n",
      "\\ faM apMarker : 136 Boulev ard Maxime Gorki, Villejuif\n",
      "\\ fa Ph on e : 06 11 88 45 28\n",
      "z Born on 24/06/2000\n",
      "\\ faAt : krombiyahya@gmail.com\n",
      "\\ faLin kedin : yahya krombi\n",
      " Driving License B\n",
      "PROFESSIONAL EXPERIENCE\n",
      "Data Scientist/ ML Engineer\n",
      "At BNP Paribas\n",
      "z September 2024-September 2025 * Paris, France\n",
      "• Built a RAG chatbot using LangChain and ChromaDB in Domino Datalab,\n",
      "capable of analyzing complex PDFs, del\n",
      "\n",
      "OFFER:\n",
      " GROUPE [RGteracars (O) Chttps://gri\n",
      "AAO DANS VOTRE INTERET cOusiehce (http s://groupecreditagricole.jobs/fr/? idgorigine:\n",
      "Chttps:/groupecreditagricole.jobs/fr/? an $=)\n",
      "\n",
      "id_origine=502)\n",
      "“<= & CREDIT AGRICOLE CIB vy\n",
      "\n",
      "Accueil (https:/groupecreditagricole.jobs/fr/?id_ origine=502)\n",
      "Nos offres (https:/groupecreditagricole.jobs/fr/nos-offres/?\n",
      "id_origine=502)\n",
      "\n",
      "Data scientist confirmé H/F\n",
      "\n",
      "cDI\n",
      "\n",
      "Data scientist confirmé H/F\n",
      "\n",
      "Modifiée le 22/05/2025\n",
      "\n",
      "9 Montrouge - France\n",
      "& IT, Digital et Data\n",
      " 2025-100600\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cv_text = extract_text_from_pdf(\"/home/yaya/rhagent/data/cvs/Cv_Yahya_KROMBI.pdf\")\n",
    "offer_text = extract_text_from_pdf(\"/home/yaya/rhagent/data/jobs/offre2.pdf\")\n",
    "\n",
    "print(\"CV:\\n\", cv_text[:500])\n",
    "print(\"\\nOFFER:\\n\", offer_text[:500])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1226b262",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai in /home/yaya/rhagent/melo_env/lib/python3.12/site-packages (1.82.0)\n",
      "Requirement already satisfied: langchain in /home/yaya/rhagent/melo_env/lib/python3.12/site-packages (0.3.25)\n",
      "Collecting langchain-community\n",
      "  Using cached langchain_community-0.3.24-py3-none-any.whl.metadata (2.5 kB)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /home/yaya/rhagent/melo_env/lib/python3.12/site-packages (from openai) (4.9.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /home/yaya/rhagent/melo_env/lib/python3.12/site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /home/yaya/rhagent/melo_env/lib/python3.12/site-packages (from openai) (0.28.1)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /home/yaya/rhagent/melo_env/lib/python3.12/site-packages (from openai) (0.10.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /home/yaya/rhagent/melo_env/lib/python3.12/site-packages (from openai) (2.11.5)\n",
      "Requirement already satisfied: sniffio in /home/yaya/rhagent/melo_env/lib/python3.12/site-packages (from openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in /home/yaya/rhagent/melo_env/lib/python3.12/site-packages (from openai) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in /home/yaya/rhagent/melo_env/lib/python3.12/site-packages (from openai) (4.13.2)\n",
      "Requirement already satisfied: idna>=2.8 in /home/yaya/rhagent/melo_env/lib/python3.12/site-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
      "Requirement already satisfied: certifi in /home/yaya/rhagent/melo_env/lib/python3.12/site-packages (from httpx<1,>=0.23.0->openai) (2025.4.26)\n",
      "Requirement already satisfied: httpcore==1.* in /home/yaya/rhagent/melo_env/lib/python3.12/site-packages (from httpx<1,>=0.23.0->openai) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in /home/yaya/rhagent/melo_env/lib/python3.12/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /home/yaya/rhagent/melo_env/lib/python3.12/site-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /home/yaya/rhagent/melo_env/lib/python3.12/site-packages (from pydantic<3,>=1.9.0->openai) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /home/yaya/rhagent/melo_env/lib/python3.12/site-packages (from pydantic<3,>=1.9.0->openai) (0.4.1)\n",
      "Requirement already satisfied: langchain-core<1.0.0,>=0.3.58 in /home/yaya/rhagent/melo_env/lib/python3.12/site-packages (from langchain) (0.3.61)\n",
      "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.8 in /home/yaya/rhagent/melo_env/lib/python3.12/site-packages (from langchain) (0.3.8)\n",
      "Requirement already satisfied: langsmith<0.4,>=0.1.17 in /home/yaya/rhagent/melo_env/lib/python3.12/site-packages (from langchain) (0.3.42)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /home/yaya/rhagent/melo_env/lib/python3.12/site-packages (from langchain) (2.0.41)\n",
      "Requirement already satisfied: requests<3,>=2 in /home/yaya/rhagent/melo_env/lib/python3.12/site-packages (from langchain) (2.32.3)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /home/yaya/rhagent/melo_env/lib/python3.12/site-packages (from langchain) (6.0.2)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /home/yaya/rhagent/melo_env/lib/python3.12/site-packages (from langchain-core<1.0.0,>=0.3.58->langchain) (9.1.2)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /home/yaya/rhagent/melo_env/lib/python3.12/site-packages (from langchain-core<1.0.0,>=0.3.58->langchain) (1.33)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in /home/yaya/rhagent/melo_env/lib/python3.12/site-packages (from langchain-core<1.0.0,>=0.3.58->langchain) (24.2)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /home/yaya/rhagent/melo_env/lib/python3.12/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.58->langchain) (3.0.0)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /home/yaya/rhagent/melo_env/lib/python3.12/site-packages (from langsmith<0.4,>=0.1.17->langchain) (3.10.18)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /home/yaya/rhagent/melo_env/lib/python3.12/site-packages (from langsmith<0.4,>=0.1.17->langchain) (1.0.0)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /home/yaya/rhagent/melo_env/lib/python3.12/site-packages (from langsmith<0.4,>=0.1.17->langchain) (0.23.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/yaya/rhagent/melo_env/lib/python3.12/site-packages (from requests<3,>=2->langchain) (3.4.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/yaya/rhagent/melo_env/lib/python3.12/site-packages (from requests<3,>=2->langchain) (2.4.0)\n",
      "Requirement already satisfied: greenlet>=1 in /home/yaya/rhagent/melo_env/lib/python3.12/site-packages (from SQLAlchemy<3,>=1.4->langchain) (3.2.2)\n",
      "Collecting aiohttp<4.0.0,>=3.8.3 (from langchain-community)\n",
      "  Downloading aiohttp-3.11.18-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.7 kB)\n",
      "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain-community)\n",
      "  Using cached dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
      "Collecting pydantic-settings<3.0.0,>=2.4.0 (from langchain-community)\n",
      "  Using cached pydantic_settings-2.9.1-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting httpx-sse<1.0.0,>=0.4.0 (from langchain-community)\n",
      "  Using cached httpx_sse-0.4.0-py3-none-any.whl.metadata (9.0 kB)\n",
      "Collecting numpy>=1.26.2 (from langchain-community)\n",
      "  Downloading numpy-2.2.6-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (62 kB)\n",
      "Collecting aiohappyeyeballs>=2.3.0 (from aiohttp<4.0.0,>=3.8.3->langchain-community)\n",
      "  Using cached aiohappyeyeballs-2.6.1-py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting aiosignal>=1.1.2 (from aiohttp<4.0.0,>=3.8.3->langchain-community)\n",
      "  Using cached aiosignal-1.3.2-py2.py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting attrs>=17.3.0 (from aiohttp<4.0.0,>=3.8.3->langchain-community)\n",
      "  Using cached attrs-25.3.0-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp<4.0.0,>=3.8.3->langchain-community)\n",
      "  Downloading frozenlist-1.6.0-cp312-cp312-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (16 kB)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp<4.0.0,>=3.8.3->langchain-community)\n",
      "  Downloading multidict-6.4.4-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.3 kB)\n",
      "Collecting propcache>=0.2.0 (from aiohttp<4.0.0,>=3.8.3->langchain-community)\n",
      "  Downloading propcache-0.3.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (10 kB)\n",
      "Collecting yarl<2.0,>=1.17.0 (from aiohttp<4.0.0,>=3.8.3->langchain-community)\n",
      "  Downloading yarl-1.20.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (72 kB)\n",
      "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
      "  Using cached marshmallow-3.26.1-py3-none-any.whl.metadata (7.3 kB)\n",
      "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
      "  Using cached typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting python-dotenv>=0.21.0 (from pydantic-settings<3.0.0,>=2.4.0->langchain-community)\n",
      "  Using cached python_dotenv-1.1.0-py3-none-any.whl.metadata (24 kB)\n",
      "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
      "  Using cached mypy_extensions-1.1.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "Using cached langchain_community-0.3.24-py3-none-any.whl (2.5 MB)\n",
      "Downloading aiohttp-3.11.18-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hUsing cached dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
      "Using cached httpx_sse-0.4.0-py3-none-any.whl (7.8 kB)\n",
      "Using cached marshmallow-3.26.1-py3-none-any.whl (50 kB)\n",
      "Downloading multidict-6.4.4-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (223 kB)\n",
      "Using cached pydantic_settings-2.9.1-py3-none-any.whl (44 kB)\n",
      "Using cached typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
      "Downloading yarl-1.20.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (349 kB)\n",
      "Using cached aiohappyeyeballs-2.6.1-py3-none-any.whl (15 kB)\n",
      "Using cached aiosignal-1.3.2-py2.py3-none-any.whl (7.6 kB)\n",
      "Using cached attrs-25.3.0-py3-none-any.whl (63 kB)\n",
      "Downloading frozenlist-1.6.0-cp312-cp312-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (316 kB)\n",
      "Using cached mypy_extensions-1.1.0-py3-none-any.whl (5.0 kB)\n",
      "Downloading numpy-2.2.6-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.5/16.5 MB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading propcache-0.3.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (245 kB)\n",
      "Using cached python_dotenv-1.1.0-py3-none-any.whl (20 kB)\n",
      "Installing collected packages: python-dotenv, propcache, numpy, mypy-extensions, multidict, marshmallow, httpx-sse, frozenlist, attrs, aiohappyeyeballs, yarl, typing-inspect, aiosignal, pydantic-settings, dataclasses-json, aiohttp, langchain-community\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17/17\u001b[0m [langchain-community]ngchain-community]\n",
      "\u001b[1A\u001b[2KSuccessfully installed aiohappyeyeballs-2.6.1 aiohttp-3.11.18 aiosignal-1.3.2 attrs-25.3.0 dataclasses-json-0.6.7 frozenlist-1.6.0 httpx-sse-0.4.0 langchain-community-0.3.24 marshmallow-3.26.1 multidict-6.4.4 mypy-extensions-1.1.0 numpy-2.2.6 propcache-0.3.1 pydantic-settings-2.9.1 python-dotenv-1.1.0 typing-inspect-0.9.0 yarl-1.20.0\n"
     ]
    }
   ],
   "source": [
    "!pip install openai langchain langchain-community\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts import ChatPromptTemplate, SystemMessagePromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "def get_rh_chain(cv_text: str, offer_text: str, chat_history: list[str]) -> LLMChain:\n",
    "    system_template = \"\"\"\n",
    "Tu es un recruteur RH bienveillant et professionnel chargé de conduire un entretien.\n",
    "\n",
    "Voici le CV du candidat :\n",
    "{cv_text}\n",
    "\n",
    "Voici l'offre d'emploi :\n",
    "{offer_text}\n",
    "\n",
    "Voici l'historique récent de l’entretien :\n",
    "{chat_history}\n",
    "\n",
    "Voici la nouvelle entrée du candidat (question ou réponse) :\n",
    "{user_input}\n",
    "\n",
    "Ta mission :\n",
    "- Si c’est une réponse, pose une question RH pertinente pour approfondir.\n",
    "- Si c’est une question, réponds naturellement, professionnellement et avec empathie.\n",
    "Sois humain, pertinent et adapté à l’échange.\n",
    "\"\"\"\n",
    "\n",
    "    prompt = ChatPromptTemplate.from_messages([\n",
    "        SystemMessagePromptTemplate.from_template(system_template)\n",
    "    ])\n",
    "\n",
    "    llm = ChatOpenAI(model=\"gpt-4o\", temperature=0.4)\n",
    "\n",
    "    return LLMChain(llm=llm, prompt=prompt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c1ecd721",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_77426/645062676.py:35: LangChainDeprecationWarning: The class `ChatOpenAI` was deprecated in LangChain 0.0.10 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import ChatOpenAI``.\n",
      "  llm = ChatOpenAI(model=\"gpt-4o\", temperature=0.4)\n",
      "/tmp/ipykernel_77426/645062676.py:37: LangChainDeprecationWarning: The class `LLMChain` was deprecated in LangChain 0.1.17 and will be removed in 1.0. Use :meth:`~RunnableSequence, e.g., `prompt | llm`` instead.\n",
      "  return LLMChain(llm=llm, prompt=prompt)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'cv_text': 'KROMBI YAHYA\\nDynamic and rigorous engineer seeking a position in the ﬁeld\\nof Data/Gen IA.\\n\\\\ faM apMarker : 136 Boulev ard Maxime Gorki, Villejuif\\n\\\\ fa Ph on e : 06 11 88 45 28\\nz Born on 24/06/2000\\n\\\\ faAt : krombiyahya@gmail.com\\n\\\\ faLin kedin : yahya krombi\\n\\x88 Driving License B\\nPROFESSIONAL EXPERIENCE\\nData Scientist/ ML Engineer\\nAt BNP Paribas\\nz September 2024-September 2025 * Paris, France\\n• Built a RAG chatbot using LangChain and ChromaDB in Domino Datalab,\\ncapable of analyzing complex PDFs, delivering real-time, actionable insights\\nto inform and support strategic decision-making (LLMs-multimodels, chro-\\nmadb, Streamlit, PDF/image-to-data extraction).\\n• Enabled multimodal analysis to interpret textual and visual data (Tesser-\\nact OCR, Vision Transformers, OpenCV, LangChain tools).\\n• Reduced external expenses and streamlined data workﬂows using GenAI\\nand LLMs for automated database queries and insight generation (Mistral,\\nLangChain agents, SQL, time series analysis).\\n• Built and deployed models for clustering, anomaly detection, and fore-\\ncasting to uncover patterns and anticipate trends (K-means, DBSCAN, Iso-\\nlation Forest, XGBoost, Prophet, LSTM).\\nData Scientist Intern (DataOPS)\\nAt EDF\\nz February 2023-July 2023\\n* Nanterre, France\\n• Created an ETL for the database of an intelligent chatbot.\\n• Developed a deep learning LSTM model for generating responses using\\nNLP methods (Generative AI).\\n• Produced a POC of the chatbot using AWS services.\\nData Analyst Intern\\nAt Setragen\\nz September 2021-February 2022\\n* Casablanca, Morocco\\n• Created and managed an authentication database (PostgreSQL).\\n• Visualized data using dashboards (Power BI).\\n• Participated in the update and design of the new Setragen website.\\nACADEMIC PROJECTS\\nAutomatic HR Agent using GenAI and Deep Learning\\n• Built an HR agent for natural language conversations, handling recruit-\\nment and employee queries with contextual understanding (LLMs, Hugging\\nFace, OpenAI).\\n• Fine-tuned models for HR-speciﬁc tasks and automated key processes\\nthrough eﬃcient deployment, testing, and integration.\\nPublic Transport Traﬃc Prediction in Paris\\n• Data analysis (Python).\\n• Machine Learning model for traﬃc prediction (Naive Bayes).\\n• Deep Learning model and comparison with Machine Learning model.\\nEDUCATION\\nMastère Spécialisé® Expert Big Data Engineer\\nUniversité de technologie de Troyes\\nz Sept 2024 – Sept 2025\\n* Paris, France\\n• Specialized training in Data Science and Data Engineering.\\n• Studied machine learning and deep learning concepts.\\n• Worked on generative AI projects, focusing on transformer architectures.\\nEngineering Cycle\\nÉCOLE NATIONALE SUPÉRIEURE DE MÉCANIQUE ET DES MI-\\nCROTECHNIQUES\\nz Sept 2019 – June 2024\\n* Besançon, France\\nGeneral training in optimization, modeling, and applied mathematics.\\nSKILLS\\n• Programming Languages:\\nPython\\nR\\nJava\\n• Data Analysis:\\nPower BI\\nTableau\\nExcel\\n• Machine Learning:\\nScikit-learn\\nPandas\\nAWS Lex\\n• Deep Learning:\\nTensorﬂow\\nPytorch\\nLLMs\\nPrompt Engineering\\n• Data Engineering Tools:\\nDocker\\nKafka\\nMongoDB\\nSpark\\n• Big Data Tools:\\nSQL/NoSQL\\nOracle Data Mining\\nGoogle Analytics\\nHadoop\\nETL\\nCloud Services\\n• Environment:\\nGitLab\\nDomino Datalab\\nLinux\\nVS Code\\nAWS\\n• Soft Skills:\\nAutonomy\\nProject Management\\nTeamwork\\nProblem Solving\\nCERTIFICATIONS\\nDeep Learning and Neural Networks\\nDeepLearning.AI - Coursera\\nz April 2022\\nCore concepts of deep learning, generative AI,\\nand sequence models.\\nImproving Deep Neural Networks:\\nHyperparameter Tuning, Regulariza-\\ntion, and Optimization\\nDeepLearning.AI - Coursera\\nz June 2022\\nOptimization techniques for deep and genera-\\ntive models.\\nAI Agent Course\\nHugging Face\\nz March 2025\\nFrom a beginner to expert, in understanding,\\nusing and building AI agents.\\nLANGUAGES\\nFrench (Bilingual)\\n4 . 5\\nEnglish (Linguaskill C1)\\n4 . 5\\nArabic (Native language)\\n5\\nINTERESTS\\nBasketball (Morocco Champion for 2 years)\\nTravel\\nMusic\\nChess\\nMathematics', 'offer_text': \"GROUPE [RGteracars (O) Chttps://gri\\nAAO DANS VOTRE INTERET cOusiehce (http s://groupecreditagricole.jobs/fr/? idgorigine:\\nChttps:/groupecreditagricole.jobs/fr/? an $=)\\n\\nid_origine=502)\\n“<= & CREDIT AGRICOLE CIB vy\\n\\nAccueil (https:/groupecreditagricole.jobs/fr/?id_ origine=502)\\nNos offres (https:/groupecreditagricole.jobs/fr/nos-offres/?\\nid_origine=502)\\n\\nData scientist confirmé H/F\\n\\ncDI\\n\\nData scientist confirmé H/F\\n\\nModifiée le 22/05/2025\\n\\n9 Montrouge - France\\n& IT, Digital et Data\\n 2025-100600\\n\\nDescription du poste\\n\\nNOUS CONNAITRE !\\nLa Direction IT and Opération Services (IOS) a pour objectif de doter CACIB de\\nla meilleure Plateforme IT et Opérations pour répondre aux besoins de maintenir\\net renforcer la qualité des services rendus a CACIB et de se préparer aux enjeux\\nde croissance et de transformation digitale de CACIB dans les années futures.\\nRejoignez la Direction |OS / Global IT (GIT) de CA-CIB, responsable de la\\nconception, du développement, de la maintenance des applications et des\\nsystémes de la Banque !\\nA la pointe de l’innovation technologique, ses équipes accompagnent sur le plan\\ntechnique et fonctionnel, les activités et projets de développement des\\ndifférents métiers de la Banque de Financements et d'Investissement dans un\\nenvironnement international.\\nEn intégrant une filiere informatique de plus de 2.500 collaborateurs, vous\\nbénéficierez de multiples opportunités professionnelles, grace a la diversité de\\nnos métiers et a nos parcours évolutifs au sein de nos entités.\\n\\nLa Direction des Systémes d’information, « Global IT », recherche un(e) :\\n\\n- Intitulé du poste H/F - Basé a Montrouge (92) -\\n\\nVOTRE EQUIPE\\n\\nCréé il y a 3 ans au sein du Digital Excellence Center, L'Al Factory (AIF) de\\nCACIB est a l'avant-garde de l'innovation technologique dans le secteur\\nbancaire.\\n\\nVOS MISSIONS\\n\\nEntant que Data Scientist vous aurez l’opportunité de travailler sur des projets\\nconcrets a fort impact dans une banque d’investissement de premier plan.\\nConcrétement vous aurez comme missions :\\n\\nImplémenter des outils innovants d'aide a la décision se basant sur IIA\\ngénérative (RAG, RAG multimodal, LLM, SLM pour un domaine\\n\\nspécifique de la Finance etc.)\\n\\nConcevoir et implémenter des solutions de traitement du langage\\nnaturel (NLP) pour l’analyse de documents financiers (classification de\\n\\ntexte, extraction d’information, NER etc.)\\n\\nDévelopper et optimiser des modéles d'lA prédictive (implémentation\\nd’algorithmes de Machine et de Deep Learning, Feature engineering\\n\\naccompagné par les métiers de la finance, etc.)\\n\\nMener des projets de recherche autour de I’IA Générative (e.g.\\n\\névaluation et mesure de I’hallucination des LLM, fine tuning de LLM etc.)\\n\\nContribuer aux taches de veille autour des sujets innovants en IA\\n\\nva\\n*‘ fe) - Contribuer aux différents travaux d’analyse et de traitement de la\\n\\ndonnée\\n\\n\\\\GRICOLE.JOBS/FR/NOS-OFFRES/?ID_ORIGINE=502)\\n\\nJE POSTULE\\nGROUPE AGIR CHAQUE JOUR Mettre en place des indicateurs et outils de validation de la performance Chttps://gr\\nCREDIT DANS VOTREINTERET ‘exalicaniité loorith coyamence Chttps://groupecreditagricole.jobs/fr/? idgorigine:\\nPNci=iteve}M=m ET CELUIDELASOCI (https: /groupecreditag henge’, Afr? gorithmes et des modele MI ORR§S ee\\n\\nid_origine=502\\nid origine Pot AGRICOLE CIB\\n\\nIntégrer les développements dans les outils existants de I’équipe et de la v\\n\\nbanque\\n\\nVous aurez ainsi l’opportunité de travailler sur des projets concrets a fort\\n\\nimpact dans une banque d’investissement de premier plan\\n\\nCritéres de candidature 4\\nEntreprise Crédit Agricole CIB 4\\n\\nNos avantages\\n\\npes Une grande Un Une stratégie de De\\ns et variété de environnement Des positions de | gestion de en\\nibles métiers international leadership carriére re}\\ndir plus En savoir plus En savoir plus En savoir plus En savoir plus\\nCes offres pourraient vous intéresser !\\nCIB CIB cIB\\nChargé d'études et réalisation de... Data Analyst - Département... Business Analyst H/F\\nALTERNANCE / APPRENTISSAGE ALTERNANCE / APPRENTISSAGE ALTERNANCE / APPRENTISSAC\\n\\nvile\\nome\\n\\n\\\\GRICOLE.JOBS/FR/NOS-OFFRES/?ID_ORIGINE=502) Xo\\nGROUPE [RGR ai Chttps://gr\\n\\nENTREE cece chttp s://groupecreditagricole.jobs/fr/? idgorigine:\\n(https s/orouneqreditacricolejobs/i7 zea ia We a“\\n\\n»\\n\\nid_origine=502\\neS olp TO AGRICOLE CIB\\n\\n: SIRF, 1.0 Bit: ‘ %AQAItAgricc\\nref_ ores twsrco6SE Megle%7Ctwcamp%e “Elerp%7 @4var%5Eauthor)\\n\\n(https “/wewvutiktok.com/@aroune ca_recrute)\\n\\n2096 OFFRES !\\n\\n=> Découvrez nos offres\\nchttps:/groupecreditagricole.jobs/fr/nos-offres/?id_ origine=502)\\n\\nNos conseils (https://groupecreditagricole.jobs/fr/nos-conseils/?id_ origine=502)\\n\\nNotre actualité (https://groupecreditagricole.jobs/fr/notre-actualite/?id_origine=502)\\n\\nSite des Caisses régionales (https://www.ca-recrute.fr/?id_origine=502) 7)\\nSite corporate (https://www.credit-agricole.com/?id_origine=502) |\\n\\nDécouvrez notre parcours d’orientation recrutement Groupe Crédit Agricole (https://decouverte.groupecreditagricole.jobs/?id_origine=502) 7|\\n\\nNos marques Wz\\nNos offres dans le monde wv\\nNos offres en France wv\\n\\nContact (https://groupecreditagricole.jobs/fr/contact/?id_ origine=502)\\nFAQ (https:/groupecreditagricole.jobs/fr/faq/?id_origine=502)\\nMentions légales (https://groupecreditagricole.jobs/fr/mentions-legales/?id_origine=502)\\nPlan du site (https:/groupecreditagricole.jobs/fr/plan-du-site/?id_origine=502)\\nGestion des cookies (?id_origine=502)\\nDéclaration d’accessibilité : non conforme (https://groupecreditagricole.jobs/fr/declaration-daccessibilite/?id_ origine=502)\\nCharte des données (https:/groupecreditagricole.jobs/fr/charte-candidats/?id_origine=502)\\n\\nvie ©2025 Groupe Crédit Agricole\\n\\n\\\\GRICOLE.JOBS/FR/NOS-OFFRES/?ID_ORIGINE=502) Xo\\nGroupe AGIR CHAQUE JOUR DANS VOTRE INTERET ET CELUI DELA SOCIETE chttps://ori\\nCREDIT _ eae 2 Wit ps://groupecreditagricole.jobs/fr/? —idsorigine:\\nMaia setcedheclie 2 CREDIT AGRICOLE psiiisroup 9 iobs/fr/?  idaorigine:\\n\\nGeQuoDSe2 02> vaditagtieale.iobs/fr/?id origine=502) L\\n\\nva\\n\\n\\\\GRICOLE.JOBS/FR/NOS-OFFRES/?ID_ORIGINE=502)\", 'chat_history': 'RH: Bonjour Yahya, pouvez-vous vous présenter ?\\nCandidat: Oui, je suis data engineer chez BNP Paribas en alternance.\\nRH: Pouvez-vous me parler d’un projet marquant ?\\nCandidat: J’ai développé un chatbot RAG pour analyser des PDFs complexes.', 'user_input': \"Ce projet m’a permis d'apprendre à intégrer LangChain avec ChromaDB.\", 'text': \"RH : C'est intéressant, Yahya. Pourriez-vous nous expliquer comment vous avez surmonté les défis techniques liés à l'intégration de LangChain avec ChromaDB ? Quels ont été les principaux obstacles et comment les avez-vous résolus ?\"}\n"
     ]
    }
   ],
   "source": [
    "chat_history = [\n",
    "    \"RH: Bonjour Yahya, pouvez-vous vous présenter ?\",\n",
    "    \"Candidat: Oui, je suis data engineer chez BNP Paribas en alternance.\",\n",
    "    \"RH: Pouvez-vous me parler d’un projet marquant ?\",\n",
    "    \"Candidat: J’ai développé un chatbot RAG pour analyser des PDFs complexes.\",\n",
    "]\n",
    "\n",
    "user_input = \"Ce projet m’a permis d'apprendre à intégrer LangChain avec ChromaDB.\"\n",
    "\n",
    "chain = get_rh_chain(cv_text, offer_text, chat_history)\n",
    "\n",
    "response = chain.invoke({\n",
    "    \"cv_text\": cv_text,\n",
    "    \"offer_text\": offer_text,\n",
    "    \"chat_history\": \"\\n\".join(chat_history),\n",
    "    \"user_input\": user_input\n",
    "})\n",
    "\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4eaf5d07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RH : C'est intéressant, Yahya. Pourriez-vous nous expliquer comment vous avez surmonté les défis techniques liés à l'intégration de LangChain avec ChromaDB ? Quels ont été les principaux obstacles et comment les avez-vous résolus ?\n"
     ]
    }
   ],
   "source": [
    "print(response[\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6878926f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "melo_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
